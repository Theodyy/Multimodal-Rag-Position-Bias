{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, AutoTokenizer\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"your/path/to/Qwen2-VL-7B-Instruct\"\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:6\",\n",
    "    attn_implementation=\"eager\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(model)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../result/attention_result\"\n",
    "save_name = \"position1_combined_result.png\"\n",
    "att_pos_path = os.path.join(save_path, \"att_pos1.json\")\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "# 配置参数\n",
    "original_paths = [    \n",
    "    \"../image/image1-chart-visual.png\",    \n",
    "    \"../image/image2-chart-visual.png\",\n",
    "    \"../image/image3-chart-visual.png\",    \n",
    "]\n",
    "save_directory = save_path\n",
    "target_dim = (1092,756)\n",
    "\n",
    "file_names = [\"att_pos1.json\", \"att_pos2.json\", \"att_pos3.json\"]\n",
    "keys = [\"figure1\", \"figure2\", \"figure3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(image_paths, save_dir, target_size=(2184,1512)):\n",
    "    \"\"\"缩放图像并返回新路径列表\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    resized_paths = []\n",
    "    \n",
    "    for idx, path in enumerate(image_paths):\n",
    "        with Image.open(path) as img:\n",
    "            # 保持原始文件名并添加尺寸后缀\n",
    "            filename = os.path.basename(path)\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            new_name = f\"{name}_{target_size[0]}x{target_size[1]}{ext}\"\n",
    "            save_path = os.path.join(save_dir, new_name)\n",
    "            \n",
    "            # 执行缩放并保存\n",
    "            resized = img.resize(target_size, Image.LANCZOS)\n",
    "            resized.save(save_path)\n",
    "            resized_paths.append(save_path)\n",
    "    \n",
    "    return resized_paths\n",
    "\n",
    "# 执行缩放并获取新路径\n",
    "processed_paths = resize_images(original_paths, save_directory, target_dim)\n",
    "\n",
    "# 构建消息结构\n",
    "prompt = \"What was the youth unemployment rate in Lebanon in 2020?\"\n",
    "#3838, 572, 279, 12537, 25608, 4379, 304, 39271( Lebanon), 304, 220(2020), 17, 15, 17, 15(2020), 30(?)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            *[{\"type\": \"image\", \"image\": path} for path in processed_paths],\n",
    "            {\"type\": \"text\", \"text\": prompt}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(text)\n",
    "print(tokenizer.encode(text))\n",
    "print(len(tokenizer.encode(text)))\n",
    "\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "print(image_inputs)\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "print(inputs.keys())\n",
    "print(inputs.pixel_values.shape)\n",
    "# 30-36\n",
    "# -7~-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1092*756的图像patch为39*27\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_attentions=True)\n",
    "    attns = outputs.attentions\n",
    "print(len(attns))\n",
    "print(attns[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 几张图片就减去几\n",
    "if attns[0].shape[-1] != len(tokenizer.encode(text)) + inputs.pixel_values.shape[0] / 4 - 3:\n",
    "    raise ValueError(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_avg = attns[14].mean(dim=1).squeeze(0)\n",
    "# 每一层\n",
    "# in Lebanon in 2020:30~36,-7~-13位置\n",
    "#inputs.pixel_values.shape[0]是所有 vision 图像的token数\n",
    "# attention_map = attention_avg[inputs.pixel_values.shape[0] // 4 + 30 - 3, 15:inputs.pixel_values.shape[0] // 12 + 15]\n",
    "attention_map = attention_avg[inputs.pixel_values.shape[0] // 4 +  27 : inputs.pixel_values.shape[0] // 4 + 33, 15:inputs.pixel_values.shape[0] // 12 + 15]\n",
    "attn_sum = attention_map.sum(axis=0)\n",
    "attn_sum = (attn_sum - attn_sum.min()) / (attn_sum.max() - attn_sum.min())\n",
    "\n",
    "image = np.array(image_inputs[0])\n",
    "heatmap = np.zeros_like(image)\n",
    "patch_size = 28\n",
    "\n",
    "for col in range(image_inputs[0].size[0] // patch_size):\n",
    "    for row in range(image_inputs[0].size[1] // patch_size):\n",
    "        x1, y1 = col * patch_size, row * patch_size\n",
    "        x2, y2 = x1 + patch_size, y1 + patch_size\n",
    "        color = cv2.applyColorMap(np.array([[int(attn_sum[row * (image_inputs[0].size[0] // patch_size) + col] * 255)]], dtype=np.uint8), cv2.COLORMAP_TURBO)[0, 0]\n",
    "        heatmap[y1:y2, x1:x2] = color\n",
    "\n",
    "overlay = cv2.addWeighted(image, 0.50, heatmap, 0.50, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(overlay)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_plot(images_list, labels=[\"position 1\", \"position 2\", \"position 3\"]):\n",
    "    # 统一图片尺寸（假设三张图尺寸相同）\n",
    "    widths, heights = zip(*(img.size for img in images_list))\n",
    "    max_width, max_height = max(widths), max(heights)\n",
    "    \n",
    "    # 创建新画布（含文字标注区域）\n",
    "    spacing = 50  # 图片间距\n",
    "    text_height = 150  # 文字区域高度\n",
    "    total_width = sum(widths) + spacing*(len(images_list)-1)\n",
    "    combined_img = Image.new('RGB', (total_width, max_height + text_height), color=(255, 255, 255))\n",
    "    \n",
    "    # 加载字体\n",
    "    font_size = 100\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"../utils/Arial.ttf\", font_size)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    draw = ImageDraw.Draw(combined_img)\n",
    "    x_offset = 0\n",
    "    \n",
    "    for idx, (img, label) in enumerate(zip(images_list, labels)):\n",
    "        # 粘贴图片\n",
    "        combined_img.paste(img, (x_offset, 0))\n",
    "        # 添加文字标注（居中显示）\n",
    "        text_width = draw.textlength(label, font=font)\n",
    "        draw.text(\n",
    "            (x_offset + (img.width - text_width)//2, max_height + 5),\n",
    "            label,\n",
    "            fill=(0, 0, 0),\n",
    "            font=font\n",
    "        )\n",
    "        x_offset += img.width + spacing\n",
    "    \n",
    "    return combined_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成不同位置对应的注意力分布热力图\n",
    "white = (255 / 255, 255 / 255, 255 / 255)\n",
    "dark_red = (255 / 255, 0 / 255, 0 / 255)\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [white, dark_red])\n",
    "\n",
    "# ========== 定义三个注意力映射 ========== \n",
    "attention_maps = {\n",
    "    \"figure1\": {\n",
    "        \"start\": 15,\n",
    "        \"end\": inputs.pixel_values.shape[0] // 12 + 15\n",
    "    },\n",
    "    \"figure2\": {\n",
    "        \"start\": 17 + inputs.pixel_values.shape[0] // 12,\n",
    "        \"end\": inputs.pixel_values.shape[0] // 6 + 17\n",
    "    },\n",
    "    \"figure3\": {\n",
    "        \"start\": 19 + inputs.pixel_values.shape[0] // 6,\n",
    "        \"end\": inputs.pixel_values.shape[0] // 4 + 19\n",
    "    }\n",
    "}\n",
    "position_attentions = {}\n",
    "temp_images = []\n",
    "position_scores = {}  # 新增：存储各位置得分\n",
    "position_fullimage_scores = {}  # 新增：存储全局得分\n",
    "for idx, (name, pos) in enumerate(attention_maps.items()):\n",
    "    # ========== 注意力映射提取 ==========\n",
    "    # attention_map = attention_avg[inputs.pixel_values.shape[0] // 4 +  27 : inputs.pixel_values.shape[0] // 4 + 33, 15:inputs.pixel_values.shape[0] // 12 + 15]\n",
    "    # attn_sum = attention_map.sum(axis=0)\n",
    "    attention_map = attention_avg[\n",
    "        inputs.pixel_values.shape[0] // 4 + 27 : inputs.pixel_values.shape[0] // 4 + 33,\n",
    "        pos[\"start\"]:pos[\"end\"]\n",
    "    ]\n",
    "    attention_map = attention_map.sum(axis=0)\n",
    "    position_attentions[name] = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min())\n",
    "    # print(idx, name, attention_map.shape)\n",
    "    # ========== 注意力得分计算 ==========\n",
    "    # 定义区域参数\n",
    "    start_row = 10\n",
    "    end_row = 18\n",
    "    patches_per_row = 23\n",
    "    # 计算索引范围\n",
    "    start_idx = (start_row - 1) * patches_per_row + 15  \n",
    "    end_idx = end_row * patches_per_row - 1 + 15     \n",
    "    region_attn = attention_map[start_idx:end_idx]\n",
    "    position_scores[name] = region_attn.mean().item()   # 计算平均值作为得分\n",
    "    # ========== 全局注意力得分计算 ==========\n",
    "    position_fullimage_scores[name] = attention_map.mean().item()  # 直接计算全局平均注意力得分\n",
    "    # ========== 热力图生成 ==========\n",
    "    image = np.array(image_inputs[idx])\n",
    "    heatmap = np.zeros_like(image)\n",
    "    num_cols = image_inputs[idx].size[0] // patch_size\n",
    "    num_rows = image_inputs[idx].size[1] // patch_size\n",
    "    for col in range(num_cols):\n",
    "        for row in range(num_rows):\n",
    "            x1, y1 = col * patch_size, row * patch_size\n",
    "            x2, y2 = x1 + patch_size, y1 + patch_size\n",
    "            idx = row * num_cols + col\n",
    "            if idx < len(position_attentions[name]):  # 防止索引越界\n",
    "                attn_value = position_attentions[name][idx].item() if hasattr(position_attentions[name][idx], \"item\") else position_attentions[name][idx]\n",
    "                color_float = custom_cmap(attn_value)\n",
    "                color_uint8 = (np.array(color_float[:3]) * 255).astype(np.uint8)\n",
    "                heatmap[y1:y2, x1:x2] = color_uint8\n",
    "\n",
    "    # ========== 图像合成与保存 ==========\n",
    "    overlay = cv2.addWeighted(image, 0.50, heatmap, 0.50, 0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(overlay)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # 动态文件名生成.生成单张图后暂存到列表\n",
    "    save_path_tmp = os.path.join(save_path, f\"{name}.png\")  # 与原有计数逻辑配合\n",
    "    plt.savefig(save_path_tmp, bbox_inches=\"tight\", dpi=300, pad_inches=0.05)\n",
    "    # 打开保存的图像并转换为 RGB\n",
    "    temp_images.append(Image.open(save_path_tmp).convert('RGB'))\n",
    "\n",
    "    plt.close()# 防止内存泄漏\n",
    "# 拼接并保存最终图像\n",
    "combined = generate_combined_plot(temp_images)\n",
    "combined.save(os.path.join(save_path, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成不同位置对应的注意力分布热力图\n",
    "# 深蓝色蒙版参数\n",
    "MASK_COLOR = (44, 56, 109)  # RGB, 0-255\n",
    "MASK_OPACITY = 0.55\n",
    "\n",
    "# 高饱和度热力图渐变（可自定义更多节点）\n",
    "HEATMAP_COLORS = [\n",
    "    (0.0, (0.1, 0.2, 0.7)),   # 深蓝\n",
    "    (0.3, (0.2, 0.75, 0.6)),  # 青绿\n",
    "    (0.6, (1.0, 0.9, 0.1)),   # 黄\n",
    "    (1.0, (1.0, 0.2, 0.0)),   # 红\n",
    "]\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [c[1] for c in HEATMAP_COLORS], N=256)\n",
    "\n",
    "def apply_blue_mask(image, mask_color=MASK_COLOR, opacity=MASK_OPACITY):\n",
    "    mask = np.full_like(image, mask_color, dtype=np.uint8)\n",
    "    return cv2.addWeighted(image, 1-opacity, mask, opacity, 0)\n",
    "\n",
    "\n",
    "# ========== 定义三个注意力映射 ========== \n",
    "attention_maps = {\n",
    "    \"figure1\": {\n",
    "        \"start\": 15,\n",
    "        \"end\": inputs.pixel_values.shape[0] // 12 + 15\n",
    "    },\n",
    "    \"figure2\": {\n",
    "        \"start\": 17 + inputs.pixel_values.shape[0] // 12,\n",
    "        \"end\": inputs.pixel_values.shape[0] // 6 + 17\n",
    "    },\n",
    "    \"figure3\": {\n",
    "        \"start\": 19 + inputs.pixel_values.shape[0] // 6,\n",
    "        \"end\": inputs.pixel_values.shape[0] // 4 + 19\n",
    "    }\n",
    "}\n",
    "position_attentions = {}\n",
    "temp_images = []\n",
    "position_scores = {}  # 新增：存储各位置得分\n",
    "position_fullimage_scores = {}  # 新增：存储全局得分\n",
    "for idx, (name, pos) in enumerate(attention_maps.items()):\n",
    "    # ========== 注意力映射提取 ==========\n",
    "    attention_map = attention_avg[\n",
    "        inputs.pixel_values.shape[0] // 4 + 27 : inputs.pixel_values.shape[0] // 4 + 33,\n",
    "        pos[\"start\"]:pos[\"end\"]\n",
    "    ]\n",
    "    attention_map = attention_map.sum(axis=0)\n",
    "    position_attentions[name] = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min())\n",
    "    # print(idx, name, attention_map.shape)\n",
    "    # ========== 热力图生成 ==========\n",
    "    image = np.array(image_inputs[idx])\n",
    "    heatmap = np.zeros_like(image)\n",
    "    num_cols = image_inputs[idx].size[0] // patch_size\n",
    "    num_rows = image_inputs[idx].size[1] // patch_size\n",
    "    for col in range(num_cols):\n",
    "        for row in range(num_rows):\n",
    "            x1, y1 = col * patch_size, row * patch_size\n",
    "            x2, y2 = x1 + patch_size, y1 + patch_size\n",
    "            idx = row * num_cols + col\n",
    "            if idx < len(attn_sum):\n",
    "                color_float = custom_cmap(attn_sum[idx])\n",
    "                color_uint8 = (np.array(color_float[:3]) * 255).astype(np.uint8)\n",
    "                heatmap[y1:y2, x1:x2] = color_uint8\n",
    "\n",
    "    # ========== 图像合成与保存 ==========\n",
    "    # 可选：高斯模糊让热力图更平滑\n",
    "    heatmap = cv2.GaussianBlur(heatmap, (35, 35), 20)\n",
    "\n",
    "    # 叠加深蓝色蒙版\n",
    "    masked_image = apply_blue_mask(image)\n",
    "\n",
    "    # 叠加热力图\n",
    "    overlay = cv2.addWeighted(masked_image, 0.4, heatmap, 0.6, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 序列化前处理 numpy/tensor → list\n",
    "position_attentions_data = {}\n",
    "for name, tensor in position_attentions.items():\n",
    "    # print(name, tensor.shape)\n",
    "    position_attentions_data[name] = tensor.to(torch.float32).cpu().numpy().tolist()  # 转换为 float32 再转换为标准列表\n",
    "# print(position_attentions_data)\n",
    "# 添加 position_scores 和 position_fullimage_scores\n",
    "position_attentions_data[\"position_scores\"] = position_scores\n",
    "position_attentions_data[\"position_fullimage_scores\"] = position_fullimage_scores\n",
    "\n",
    "# 保存到文件\n",
    "with open(att_pos_path, 'w') as f:\n",
    "    json.dump(position_attentions_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成差异热图\n",
    "def plot_diff_heatmap(diff_matrix, save_path):\n",
    "    # 创建包含三列子图的画布\n",
    "    fig = plt.figure(figsize=(24, 8))\n",
    "    gs = fig.add_gridspec(1, 3, wspace=0.15)\n",
    "    \n",
    "    # 颜色映射定义\n",
    "    diff_cmap = LinearSegmentedColormap.from_list(\"diff_cmap\", [\"blue\", \"white\", \"red\"])\n",
    "    norm = plt.Normalize(vmin=-1, vmax=1)\n",
    "    \n",
    "    # 共享颜色条\n",
    "    cax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    \n",
    "    for idx, (diff_name, diff) in enumerate(diff_matrix.items()):\n",
    "        ax = fig.add_subplot(gs[0, idx])\n",
    "        \n",
    "        # 数据转换\n",
    "        diff_np = diff.to(torch.float32).cpu().detach().numpy()\n",
    "        num_cols = image_inputs[0].size[0] // patch_size\n",
    "        num_rows = image_inputs[0].size[1] // patch_size\n",
    "        diff_grid = diff_np.reshape(num_rows, num_cols).T\n",
    "        \n",
    "        # 获取原始图像\n",
    "        image = np.array(image_inputs[2])\n",
    "        \n",
    "        # 绘制底片原图\n",
    "        ax.imshow(image)\n",
    "        \n",
    "        # 叠加半透明热力层\n",
    "        heatmap = ax.imshow(\n",
    "            diff_grid,\n",
    "            cmap=diff_cmap,\n",
    "            norm=norm,\n",
    "            alpha=0.9,\n",
    "            extent=[0, image.shape[1], image.shape[0], 0],  # 匹配原图尺寸\n",
    "            interpolation='bilinear'  # nearest保持patch边界\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f\"{diff_name.replace('-', ' vs ')}\", fontsize=14)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        if idx == 2:\n",
    "            fig.colorbar(heatmap, cax=cax, orientation='vertical')\n",
    "    \n",
    "    plt.subplots_adjust(left=0.05, right=0.9, top=0.85)\n",
    "    tmp_path = os.path.join(save_path, \"combined_diff.png\")\n",
    "    plt.savefig(tmp_path, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()\n",
    "    temp_images.append(Image.open(tmp_path).convert('RGB'))\n",
    "    \n",
    "# 加载保存的数据\n",
    "# 初始化 position_attentions 字典\n",
    "position_attentions = {}\n",
    "for file_name, key in zip(file_names, keys):\n",
    "    file_path = os.path.join(save_path, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        loaded_data = json.load(f)\n",
    "    # 提取对应的值并转换为 tensor\n",
    "    position_attentions[key] = torch.tensor(loaded_data[key], dtype=torch.float32)\n",
    "for name, tensor in position_attentions.items():\n",
    "    print(name, tensor.shape)\n",
    "diff_matrix = {\n",
    "    \"pos1-pos2\": position_attentions[\"figure1\"] - position_attentions[\"figure2\"],\n",
    "    \"pos1-pos3\": position_attentions[\"figure1\"] - position_attentions[\"figure3\"],\n",
    "    \"pos2-pos3\": position_attentions[\"figure2\"] - position_attentions[\"figure3\"]\n",
    "}\n",
    "plot_diff_heatmap(diff_matrix, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tensor in position_attentions.items():\n",
    "    print(name, tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"关键区域注意力得分:\")\n",
    "for name, score in position_scores.items():\n",
    "    print(f\"{name}: {score}\")\n",
    "\n",
    "print(\"全局注意力得分:\")\n",
    "for name, score in position_fullimage_scores.items():\n",
    "    print(f\"{name}: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
